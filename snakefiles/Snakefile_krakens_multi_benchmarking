#Comparing several krakens
#multi - many samples in parallel
#
## Required config parameters:
# SAMPLE - passed with config file


# hardcoded parameters:
mainfolder='/home/ubuntu/EukBook'


rule all:
    input:
        # the samples themselves
        #expand("{sample}/reads_1.fastq.gz", sample=config["SAMPLE"]),
        #"reads_2.fastq.gz",
        #"reads_1_trim.fastq.gz",
        #"reads_2_trim.fastq.gz",
     # can be ommited in benchmarking   
        #"reads_1_fastqc.html",
        #"reads_2_fastqc.html",      
        #"reads_1_trim_fastqc.html",
        #"reads_2_trim_fastqc.html",
     # kraken classification
        expand("{sample}/my_kraken_db_prot_euk_k15_l12_output", sample=config["SAMPLE"]),
        expand("{sample}/my_kraken_db_nr_output", sample=config["SAMPLE"]),
        expand("{sample}/my_kraken_db_nt_output", sample=config["SAMPLE"]), #wildcard {config["krakendb"]} or {krakendb} don`t work anywhere except shell field
        #"Euk_reads_from_kraken_nr.txt",
     # filtered pathway
        #"ieads_1_euk.fastq.gz",
        #"reads_2_euk.fastq.gz",
        #"megahit_filtered/final.contigs.fa",
        #"megahit_filtered_full/final.contigs.fa",
        #"megahit_filtered_nt/final.contigs.fa",
        #"megahit_filtered_nr/final.contigs.fa",
        #"EukRep_contigs_from_filtered.fasta",
        ##"bowtie2_filtered.sam"
     # unfiltered pathway
        #"megahit_unfiltered/final.contigs.fa",      # --min-contig-len 5000
        expand("{sample}/EukRep_contigs_from_unfiltered.fasta", sample=config["SAMPLE"]),   # -m lenient
        #"bowtie2_unfiltered.sam",                  # --local --no-sec-seq
        #"Euk_contig_IDs_unfiltered.txt",
        expand("{sample}/mapped_reads_percentages_three_krakens.tsv", sample=config["SAMPLE"]),
	expand("{sample}/quast", sample=config["SAMPLE"])


### Preprocessing
rule download_fastq:
    output: 
        "{sample}/reads_1.fastq.gz",
        "{sample}/reads_2.fastq.gz"
    shell: 
        "{mainfolder}/scripts/download_fastq_short.sh {wildcards.sample} {output}" 


rule FastQC_untrimmed:
    input:
        "{sample}/reads_1.fastq.gz",
        "{sample}/reads_2.fastq.gz"
    output:
        "{sample}/reads_1_fastqc.html",
        "{sample}/reads_2_fastqc.html"
    conda:
        mainfolder + "/yaml/conda_packages.yaml"
    shell: 
        "fastqc -t 2 {input} "

        
rule fastp_trimming:
    input: 
        "{sample}/reads_1.fastq.gz",
        "{sample}/reads_2.fastq.gz"
    output: 
        "{sample}/reads_1_trim.fastq.gz",
        "{sample}/reads_2_trim.fastq.gz" 
    threads: 4  
    conda:
        mainfolder + "/yaml/conda_packages.yaml"
    shell: 
        "fastp -r -w {threads} -i {input[0]} -I {input[1]} -o {output[0]} -O {output[1]} -j {wildcards.sample}/fastp.json -h {wildcards.sample}/fastp.html"


rule FastQC_trimmed:
    input:
        "{sample}/reads_1_trim.fastq.gz",
        "{sample}/reads_2_trim.fastq.gz"
    output:
        "{sample}/reads_1_trim_fastqc.html",
        "{sample}/reads_2_trim_fastqc.html"
        #output is the input without extentiuon plus "_fastqc.html". And "_fastqc.zip".
    conda:
        mainfolder + "/yaml/conda_packages.yaml"
    shell:
        "fastqc -t 2 {input} "


rule kraken2_full:
    input:
        "/mnt/kraken/my_kraken_db_prot_euk_k15_l12",
        "{sample}/reads_1_trim.fastq.gz",
        "{sample}/reads_2_trim.fastq.gz"
    output:
        "{sample}/my_kraken_db_prot_euk_k15_l12_report",
        "{sample}/my_kraken_db_prot_euk_k15_l12_output"
    threads: 10 
    conda:
        mainfolder+ "/yaml/kraken2.yaml"
    resources:
        mem_mb=10000
    shell:
        "kraken2 --db {input[0]} --paired --threads {threads} "
        "--report {output[0]} --output {output[1]} {input[1]} {input[2]}"

rule kraken2_nr:
    input:
        "/mnt/kraken/my_kraken_db_nr",
        "{sample}/reads_1_trim.fastq.gz",
        "{sample}/reads_2_trim.fastq.gz"
    output:
        "{sample}/my_kraken_db_nr_report",
        "{sample}/my_kraken_db_nr_output"
    threads: 10
    resources:
        mem_mb=110000
    conda:
        mainfolder+ "/yaml/kraken2.yaml"
    shell:
        "kraken2 --db {input[0]} --paired --threads {threads} "
        "--report {output[0]} --output {output[1]} {input[1]} {input[2]}"
rule kraken2_nt:
    input:
        "/mnt/kraken/my_kraken_db_nt",
        "{sample}/reads_1_trim.fastq.gz",
        "{sample}/reads_2_trim.fastq.gz"
    output:
        "{sample}/my_kraken_db_nt_report",
        "{sample}/my_kraken_db_nt_output"
    threads: 10
    resources:
        mem_mb=170000
    conda:
        mainfolder+ "/yaml/kraken2.yaml"
    shell:
        "kraken2 --db {input[0]} --paired --threads {threads} "
        "--report {output[0]} --output {output[1]} {input[1]} {input[2]}"


rule Euk_read_ids_from_kraken_output_full:
    input:
        "{sample}/my_kraken_db_prot_euk_k15_l12_output",
        mainfolder + "/ArchBactVir_TaxIDs.txt"
    output:
        "{sample}/Euk_reads_from_kraken_full.txt"
    #conda:
    #    "python.yaml"
    shell:
        "python {mainfolder}/scripts/get_euk_read_ids_from_kraken_output.py {input[0]} {output}"

rule Euk_read_ids_from_kraken_output_nr:
    input:
        "{sample}/my_kraken_db_nr_output",
        mainfolder + "/ArchBactVir_TaxIDs.txt"
    output:
        "{sample}/Euk_reads_from_kraken_nr.txt"
    #conda:
    #    "python.yaml"
    shell:
        "python {mainfolder}/scripts/get_euk_read_ids_from_kraken_output.py {input[0]} {output}"

rule Euk_read_ids_from_kraken_output_nt:
    input:
        "{sample}/my_kraken_db_nt_output",
        mainfolder + "/ArchBactVir_TaxIDs.txt"
    output:
        "{sample}/Euk_reads_from_kraken_nt.txt"
    #conda:
    #    "python.yaml"
    shell:
        "python {mainfolder}/scripts/get_euk_read_ids_from_kraken_output.py {input[0]} {output}"





### Assembly without filtering
rule megahit_unfiltered:
    input:
        "{sample}/reads_1_trim.fastq.gz",
        "{sample}/reads_2_trim.fastq.gz"
    output:
        "{sample}/megahit_unfiltered/final.contigs.fa"
    benchmark:
        "{sample}/time_megahit_unfiltered.tsv"
    conda:
        mainfolder + "/yaml/megahit.yaml"
    shell:
        "rm -r {wildcards.sample}/megahit_unfiltered; "
	"time megahit -1 {input[0]} -2 {input[1]} -o '{wildcards.sample}/megahit_unfiltered' #--min-contig-len 5000"

rule EukRep_unfiltered:
    input:
        "{sample}/megahit_unfiltered/final.contigs.fa"
    output:
        "{sample}/EukRep_contigs_from_unfiltered.fasta"
    shell:
        "EukRep -i {input} -o {output} -m lenient --min 1"





### 1 Assembly with filtering full
rule seqtk_euk_subsetting_full_1:
    input:
        "{sample}/reads_1_trim.fastq.gz",
        "{sample}/Euk_reads_from_kraken_full.txt"
    output:
        "{sample}/reads_1_euk_full.fastq.gz"
    conda:
        mainfolder + "/yaml/seqtk.yaml"
    shell:
        "seqtk subseq {input} > {wildcards.sample}/reads_1_euk_full.fastq; "
        "gzip {wildcards.sample}/reads_1_euk_full.fastq"


rule seqtk_euk_subsetting_full_2:
     input:
         "{sample}/reads_2_trim.fastq.gz",
         "{sample}/Euk_reads_from_kraken_full.txt"
     output:
         "{sample}/reads_2_euk_full.fastq.gz"
     conda:
         mainfolder + "/yaml/seqtk.yaml"
     shell:
         "seqtk subseq {input} > {wildcards.sample}/reads_2_euk_full.fastq; "
         "gzip {wildcards.sample}/reads_2_euk_full.fastq"


rule megahit_filtered_full:
    input:
       "{sample}/reads_1_euk_full.fastq.gz",
       "{sample}/reads_2_euk_full.fastq.gz",
       expand("{samples}/mapped_reads_percentages_three_krakens.tsv", samples=config["SAMPLE"]) #just to make sure to calculate results table first
    output:
       "{sample}/megahit_filtered_full/final.contigs.fa"
    benchmark:
        "{sample}/time_megahit_filtered_full.tsv"
    conda:
        mainfolder + "/yaml/megahit.yaml"
    shell:
        "rm -r {wildcards.sample}/megahit_filtered_full; "
        "time megahit -1 {input[0]} -2 {input[1]} -o '{wildcards.sample}/megahit_filtered_full' #--min-contig-len 5000 "

### 2 Assembly with filtering nr
rule seqtk_euk_subsetting_nr_1:
    input:
        "{sample}/reads_1_trim.fastq.gz",
        "{sample}/Euk_reads_from_kraken_nr.txt"
    output:
        "{sample}/reads_1_euk_nr.fastq.gz"
    conda:
        mainfolder + "/yaml/seqtk.yaml"
    shell:
        "seqtk subseq {input} > {wildcards.sample}/reads_1_euk_nr.fastq; "
        "gzip {wildcards.sample}/reads_1_euk_nr.fastq"


rule seqtk_euk_subsetting_nr_2:
     input:
         "{sample}/reads_2_trim.fastq.gz",
         "{sample}/Euk_reads_from_kraken_nr.txt"
     output:
         "{sample}/reads_2_euk_nr.fastq.gz"
     conda:
         mainfolder + "/yaml/seqtk.yaml"
     shell:
         "seqtk subseq {input} > {wildcards.sample}/reads_2_euk_nr.fastq; "
         "gzip {wildcards.sample}/reads_2_euk_nr.fastq"


rule megahit_filtered_nr:
    input:
       "{sample}/reads_1_euk_nr.fastq.gz",
       "{sample}/reads_2_euk_nr.fastq.gz",
       expand("{samples}/mapped_reads_percentages_three_krakens.tsv", samples=config["SAMPLE"]) #just to make sure to calculate results table first
    output:
       "{sample}/megahit_filtered_nr/final.contigs.fa"
    benchmark:
        "{sample}/time_megahit_filtered_nr.tsv"
    conda:
        mainfolder + "/yaml/megahit.yaml"
    shell:
        "rm -r {wildcards.sample}/megahit_filtered_nr; "
        "time megahit -1 {input[0]} -2 {input[1]} -o '{wildcards.sample}/megahit_filtered_nr' #--min-contig-len 5000 "

### 3 Assembly with filtering nt
rule seqtk_euk_subsetting_nt_1:
    input:
        "{sample}/reads_1_trim.fastq.gz",
        "{sample}/Euk_reads_from_kraken_nt.txt"
    output:
        "{sample}/reads_1_euk_nt.fastq.gz"
    conda:
        mainfolder + "/yaml/seqtk.yaml"
    shell:
        "seqtk subseq {input} > {wildcards.sample}/reads_1_euk_nt.fastq; "
        "gzip {wildcards.sample}/reads_1_euk_nt.fastq"


rule seqtk_euk_subsetting_nt_2:
     input:
         "{sample}/reads_2_trim.fastq.gz",
         "{sample}/Euk_reads_from_kraken_nt.txt"
     output:
         "{sample}/reads_2_euk_nt.fastq.gz"
     conda:
         mainfolder + "/yaml/seqtk.yaml"
     shell:
         "seqtk subseq {input} > {wildcards.sample}/reads_2_euk_nt.fastq; "
         "gzip {wildcards.sample}/reads_2_euk_nt.fastq"


rule megahit_filtered_nt:
    input:
       "{sample}/reads_1_euk_nt.fastq.gz",
       "{sample}/reads_2_euk_nt.fastq.gz",
       expand("{samples}/mapped_reads_percentages_three_krakens.tsv", samples=config["SAMPLE"]) #just to make sure to calculate results table first
    output:
       "{sample}/megahit_filtered_nt/final.contigs.fa"
    benchmark:
        "{sample}/time_megahit_filtered_nt.tsv"
    conda:
        mainfolder + "/yaml/megahit.yaml"
    shell:
        "rm -r {wildcards.sample}/megahit_filtered_nt; "
        "time megahit -1 {input[0]} -2 {input[1]} -o '{wildcards.sample}/megahit_filtered_nt' #--min-contig-len 5000 "




### Mapping reads back to UNfiltered contigs
rule bowtie2_index_unfiltered:
    input:
        "{sample}/megahit_unfiltered/final.contigs.fa"
    output:
        "{sample}/megahit_unfiltered/final.contigs.fa.1.bt2l"
    conda:
        mainfolder + "/yaml/bowtie2.yaml"
    threads: 60
    shell: "bowtie2-build -q --large-index --threads {threads} {input} {wildcards.sample}/megahit_unfiltered/final.contigs.fa"
        

rule bowtie2_map_unfiltered:
    input:
        "{sample}/megahit_unfiltered/final.contigs.fa.1.bt2l",
        "{sample}/reads_1_trim.fastq.gz",
        "{sample}/reads_2_trim.fastq.gz"
    output:
        "{sample}/bowtie2_unfiltered.sam"
    conda:
        mainfolder + "/yaml/bowtie2.yaml"
    threads: 60
    benchmark:
        "{sample}/time_bowtie2_unfiltered.tsv"
    shell:
        "bowtie2 --local --omit-sec-seq -t --threads {threads} "
        "-x {wildcards.sample}/megahit_unfiltered/final.contigs.fa -1 {input[1]} -2 {input[2]} -S {output} 2>{wildcards.sample}/bowtie2_local_unfiltered.log"


### Checking which of reads mapped to euk contigs are actually non-Euks by Kraken opinion
rule get_Euk_contig_names_unfiltered:
    input:
        "{sample}/EukRep_contigs_from_unfiltered.fasta"
    output:
        "{sample}/Euk_contig_IDs_unfiltered.txt"
    shell:
        "grep -Eo '^>[^ ]+' {input} | cut -c 2- > {output}"


rule calculate_mapped_read_percentages_full:
    input:
        #has to be in this particular order for python script
        "{sample}/bowtie2_unfiltered.sam",
        "{sample}/Euk_contig_IDs_unfiltered.txt",
        "{sample}/Euk_reads_from_kraken_full.txt",
        "{sample}/Euk_reads_from_kraken_nr.txt",
        "{sample}/Euk_reads_from_kraken_nt.txt",

    output:
        "{sample}/mapped_reads_percentages_three_krakens.tsv"
    #conda:
    #    "python.yaml"
    shell:
        "python {mainfolder}/scripts/python_calculate_mapped_read_percentages_multiple_krakens.py {input} {output} {wildcards.sample}"


rule QUAST:
    input:
        "{sample}/megahit_unfiltered/final.contigs.fa",
        "{sample}/megahit_filtered_full/final.contigs.fa",
        "{sample}/megahit_filtered_nt/final.contigs.fa",
        "{sample}/megahit_filtered_nr/final.contigs.fa"
    output:
        directory("{sample}/quast")
    conda:
        mainfolder + "/yaml/quast.yaml"
    threads: 56
    shell:
        "quast -t {threads} -o {output} {input}"
 
